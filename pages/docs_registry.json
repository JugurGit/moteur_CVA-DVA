{
  "src/credit/entities.py": {
    "title": "Entités crédit — Counterparty / Bank + calibration à partir d’un spread initial",
    "tags": ["credit", "entities", "intensity", "LogOU", "CVA", "DVA"],
    "summary": "- **Rôle** : définit les entités crédit (contrepartie et banque) avec LGD + spread initial, et construit leurs paramètres d’intensité via un modèle Log-OU.\n- **Utilisation dans le projet** : Créer des objets `Counterparty` (avec un `Swap` pour l’exposition) et `Bank`, puis instancier leurs modèles d’intensité (`LogOUIntensity`) pour simuler PD / intensité et alimenter CVA/DVA.\n- Représenter les caractéristiques des contreparties fournies par Amerisc \n- **Objets clés** :\n  - `CreditParams` : conteneur (kappa, sigma, theta, x0) prêt à l’emploi.\n  - `build_credit_params_from_spread` : convertit `spread0` + `LGD` en paramètres Log-OU (via `lambda_bar = spread0/LGD`).\n  - `Counterparty` : entité contrepartie + produit `swap` (driver d’exposition) + méthode `make_model()`.\n  - `Bank` : entité banque (sans produit) + méthode `make_model()`.",
    "usage": "```python\nfrom credit.entities import Counterparty, Bank\nfrom products.swap import Swap\n\nswap = Swap(...)  # ton produit exposition\n\n# Contrepartie : calibration à partir d’un spread initial\ncpty = Counterparty.from_spread(\n    cid=\"CPTY_001\",\n    LGD=0.60,\n    spread0=0.015,      # 150 bps = 0.015\n    kappa_lambda=1.50,\n    sigma_lambda=0.35,\n    swap=swap,\n)\n\n# Banque : même logique (sans swap)\nbank = Bank.from_spread(\n    LGD=0.45,\n    spread0=0.010,\n    kappa_lambda=1.20,\n    sigma_lambda=0.25,\n)\n\n# Modèles d’intensité prêts pour la simu\ncpty_intensity = cpty.make_model()\nbank_intensity = bank.make_model()\n```",
    "notes": "- Hypothèse : `spread0` est en **décimal annuel** (ex: 150 bps -> `0.015`) et `LGD ∈ (0,1]`."
  }, 
  "src/credit/log_ou_intensity.py": {
    "title": "Log-OU Intensity — simulation exacte d’une intensité de défaut λ(t)=exp(x(t))",
    "tags": ["credit", "intensity", "LogOU", "simulation", "PD", "survival"],
    "summary": "- **Rôle** : implémente un modèle d’intensité de défaut **log-OU** où `x(t)=log(λ(t))` suit un Ornstein–Uhlenbeck, garantissant `λ(t)>0` via exponentielle.\n- **Utilisation dans le projet** : simuler, sur une grille de temps uniforme (`TimeGrid`), les trajectoires de `λ`, la **survie** `S(t)=exp(-∫λ ds)` et les **PD marginales** (par pas) pour alimenter les calculs CVA/DVA (via PD, EPE/ENE, DF, etc.).\n- **Objets clés** :\n  - `LogOUIntensity` : paramètres (kappa, sigma, theta, x0) + validation basique.\n  - `theta_from_lambda_bar` : calibration de `theta` pour viser une moyenne long-terme de l’intensité (`E[λ]∞ ≈ λ̄`).\n  - `simulate` : simulation **exacte** (transition Gaussienne de OU) sur grille uniforme + intégration trapèzes pour `S` et calcul de `PD`.",
    "usage": "```python\nimport numpy as np\nfrom core.timegrid import TimeGrid\nfrom credit.log_ou_intensity import LogOUIntensity\n\n# Grille uniforme (ex: 0 -> 5 ans, pas trimestriel)\ngrid = TimeGrid(T=5.0, dt=0.25)\n\n# Paramètres intensité\nlam_bar = 0.02\nkappa, sigma = 1.2, 0.4\ntheta = LogOUIntensity.theta_from_lambda_bar(lam_bar, kappa, sigma)\nmodel = LogOUIntensity(kappa=kappa, sigma=sigma, theta=theta, x0=np.log(lam_bar))\n\nrng = np.random.default_rng(2026)\nlam, S, PD = model.simulate(N=10000, grid=grid, rng=rng)\n\n# lam, S, PD : (N, K+1)\n# PD[:,0]=0, PD[:,k]=S[:,k-1]-S[:,k]\n```",
    "notes": "- **Convention PD** : `PD[:,k]` est la proba de défaut **marginale sur (t_{k-1}, t_k]** (et `PD[:,0]=0`)."
  }, 
  "src/exposure/exposure_engine.py": {
    "title": "Exposure Engine IRS — MTM scénarios + profils EPE/ENE (sans CSA)",
    "tags": ["credit", "exposure", "IRS", "EPE", "ENE", "HW1F", "MonteCarlo"],
    "summary": "- **Rôle** : calcule l’exposition d’un **swap IRS vanilla** (sans CSA / sans netting) à partir de chemins de taux courts `r[n,k]` simulés sur une `TimeGrid`.\n- **Utilisation dans le projet** : produire les profils `EPE(t_k)` et `ENE(t_k)` (et/ou les chemins MTM `V[n,k]`) nécessaires aux calculs **CVA/DVA** (ex: intégration avec PD, DF).\n- **Objets clés** :\n  - `_CoeffAtTime` : structure interne de coefficients affines pré-calculés (A,B) + accruals `alpha` pour accélérer les prix des ZC.\n  - `ExposureEngine` : moteur d’exposition basé sur un pricer zéro-coupon **affine HW** (`ZCAnalyticHW`).\n    - `_precompute_coeffs_for_time` / `_coeffs` : cache des (A,B) par date de grille pour vectoriser le pricing.\n    - `epe_ene` : retourne `EPE` et `ENE` sur la grille.\n    - `mtm_paths` : retourne `V[n,k]` (audit / plots).",
    "usage": "```python\nimport numpy as np\nfrom core.timegrid import TimeGrid\nfrom rates.zc_pricer import ZCAnalyticHW\nfrom products.swap import Swap\nfrom credit.exposure_engine import ExposureEngine\n\n# Grille de simu (ex: mensuelle sur 10 ans)\ngrid = TimeGrid(T=10.0, dt=1.0/12.0)\n\n# Pricer ZC HW analytique (A(t,T), B(t,T), P(t,T)=A*exp(-B*r_t))\nzc = ZCAnalyticHW(curve=..., a=0.03, sigma=0.01)\n\n# Swap exposition\nswap = Swap(notional=1e7, coupon=0.03, direction=\"payer_fix\", schedule=...)\n\n# Chemins de taux courts r[n,k]\nrates = ...  # (N, K+1)\n\nengine = ExposureEngine(zc)\nEPE, ENE = engine.epe_ene(rates=rates, grid=grid, swap=swap)\nV = engine.mtm_paths(rates=rates, grid=grid, swap=swap)\n```",
    "notes": "- **Hypothèse produit** : IRS vanilla **sans CSA**, et pas de netting entre trades (un swap -> un profil).\n- **Approximation jambe flottante** : le float est calculé via l’approximation robuste\n  `Float(t) ≈ 1 - P(t, T_last)` en posant `P_prev(t)=1` (donc `A_prev=1, B_prev=0`)."
  }, 
    "src/products/swap.py": {
    "title": "Swap IRS vanilla — fixed vs float (HW1F++) + par rate + roll (rebase as-of)",
    "tags": ["rates", "IRS", "swap", "HW1F", "pricing", "exposure", "EPE"],
    "summary": "- **Rôle** : définit un **swap fixed-for-float** (monodevise) et ses méthodes de pricing sous **HW1F++** via un pricer ZC affine (`ZCAnalyticHW`).\n- **Utilisation dans le projet** :\n  - calculer le **MTM** scénario par scénario (exposition) ou ponctuellement,\n  - obtenir le **par rate** à une date `t`,\n  - **roller** le swap à une nouvelle date as-of `t_star` (utile pour rejouer un run à partir d’un état déjà avancé).\n- **Objets clés** :\n  - `Swap` : instrument (notional, direction, coupon, schedule) + pricing.\n    - `_annuity` : jambe fixe restante (annuité) `Σ α_j P(t,T_j)`.\n    - `_float_leg` : jambe flottante (approx propre) `P(t,T_prev) - P(t,T_last)`.\n    - `par_rate` : `Float/Annuity`.\n    - `mtm` / `mtm_vector` : valorisation signée selon `direction`.\n  - `roll_swap` : reconstruit un swap équivalent en temps relatif en retranchant `t_star` aux dates futures.",
    "usage": "```python\nimport numpy as np\nfrom products.schedule import Schedule\nfrom products.swap import Swap, roll_swap\nfrom rates.zc_pricer import ZCAnalyticHW\n\nschedule = Schedule(...)  # ou ExplicitSchedule\nswap = Swap(\n    notional=1e7,\n    direction=\"payer_fix\",\n    coupon=0.03,\n    schedule=schedule,\n)\n\nzc = ZCAnalyticHW(curve=..., a=0.03, sigma=0.01)\n\n# MTM et par rate à t=2 ans, pour un r_t donné\nt = 2.0\nr_t = 0.015\nv = swap.mtm(t=t, r_t=r_t, zc=zc)\nKpar = swap.par_rate(t=t, r_t=r_t, zc=zc)\n\n# Vectorisation simple (plusieurs scénarios au même t)\nr_vec = np.array([0.01, 0.015, 0.02])\nV = swap.mtm_vector(t=t, r_vec=r_vec, zc=zc)\n\n# Roll : rebase le swap à une nouvelle date as-of t_star\nswap_rolled = roll_swap(swap, t_star=1.0)\n```",
    "notes": "- **Convention de signe** :\n  - `payer_fix` : `V = N * (Float - K * Annuity)`\n  - `receiver_fix` : `V = N * (K * Annuity - Float)`"
  }, 
  "src/rates/hw1f.py": {
    "title": "Hull–White 1F++ — fit de θ(t) à une courbe + simulation stable du short rate",
    "tags": ["HW1F", "rates", "model", "theta(t)", "termstructure", "MonteCarlo"],
    "summary": "- **Rôle** : implémente un **Hull–White 1 facteur en version HW++** avec **θ(t) dépendant du temps**, calibré pour recoller exactement une structure initiale via l’identité HW++.\n- **Utilisation dans le projet** :\n  - construire `theta_fn(t)` à partir d’une `TermStructure` (`inst_forward`) pour assurer la cohérence modèle/courbe,\n  - simuler des **trajectoires de short rate** `r[n,k]` sur un `TimeGrid` pour alimenter les moteurs d’exposition (EPE/ENE), CVA/DVA, etc.\n- **Objets clés** :\n  - `HW1FModel` : contient `(kappa, sigma)` + `theta_fn`.\n    - `fit_theta_to_curve(ts, grid)` : fabrique et stocke `theta_fn(t)`.\n    - `simulate_rates(N, grid, r0, rng)` : génère `r` sur la grille avec un pas OU stable (variance exacte) et moyenne variable.",
    "usage": "```python\nimport numpy as np\nfrom core.timegrid import TimeGrid\nfrom rates.hw1f import HW1FModel\nfrom rates.termstructure.base_curve import TermStructure\n\n# Courbe / term structure (doit fournir inst_forward(t))\nts = TermStructure(...)\n\n# Grille de simulation\ngrid = TimeGrid(T=10.0, K=120)  # ex: mensuel\n\n# Modèle\nmodel = HW1FModel(kappa=0.03, sigma=0.01)\n\n# Fit de theta(t) à la courbe initiale\ntheta_fn = model.fit_theta_to_curve(ts, grid)\n\n# Simulation\nrng = np.random.default_rng(2025)\nr = model.simulate_rates(N=20000, grid=grid, r0=ts.short_rate0(), rng=rng)\n# r.shape == (20000, grid.K+1)\n```",
    "notes": "- **Identité HW++ utilisée** : `theta(t) = f(0,t) + (1/kappa)*df/dt + (sigma^2/(2*kappa^2))*(1 - exp(-2*kappa*t))`."
  }, 
  "src/rates/zc_pricer.py": {
    "title": "ZC pricer HW1F++ — fonctions affines A(t,T), B(t,T) et prix P(t,T)",
    "tags": ["rates", "HW1F", "ZC", "bond", "affine", "theta(t)", "analytics"],
    "summary": "- **Rôle** : pricer analytique de **zéro-coupons** sous Hull–White 1F++ via la forme affine\n  \\(P(t,T)=A(t,T)\\exp(-B(t,T)r_t)\\).\n- **Utilisation dans le projet** :\n  - fournir `A(t,T)`, `B(t,T)` et `P(t,T)` aux produits taux (swap) et aux moteurs risques (exposure engine / EPE-ENE),\n  - garantir le **recollage exact** à la courbe initiale à `t=0` via `ts.discount_factor(T)`.\n- **Objets clés** :\n  - `ZCAnalyticHW` : façade de pricing ZC adossée à `HW1FModel` (paramètres + `theta_fn`) et `TermStructure` (DF initiaux).\n  - `B(t,T)` : coefficient affine closed-form.\n  - `A(t,T)` : via intégrale pondérée de `theta` + variance intégrée de l’OU.\n  - `P(t,r_t,T)` / `P_vector(...)` : prix ZC scalaire et vectorisé.",
    "usage": "```python\nimport numpy as np\nfrom rates.hw1f import HW1FModel\nfrom rates.zc_pricer import ZCAnalyticHW\nfrom rates.termstructure.base_curve import TermStructure\nfrom core.timegrid import TimeGrid\n\n# Term structure + modèle\ncts = TermStructure(...)\nmodel = HW1FModel(kappa=0.03, sigma=0.01)\n\n# Fit theta(t) au préalable\nmodel.fit_theta_to_curve(cts, TimeGrid(T=10.0, K=120))\n\n# Pricer ZC\nzc = ZCAnalyticHW(hw=model, ts=cts)\n\n# Prix ZC\nP_1y = zc.P(t=0.0, r_t=cts.short_rate0(), T=1.0)   # = DF(0,1) exact\nP_5y = zc.P(t=2.0, r_t=0.02, T=5.0)\n\n# Vectorisé\nTs = [3.0, 4.0, 5.0]\nP_vec = zc.P_vector(t=1.0, r_t=0.015, T_list=Ts)\n```",
    "notes": "- **Pré-requis** : `hw.theta_fn` doit être défini (via `HW1FModel.fit_theta_to_curve`) sinon `_integral_theta_weighted` lève une erreur.\n- **Recollage à t=0** : `P(0,T)` renvoie **directement** `ts.discount_factor(T)` (indépendant de `r_t`) pour éviter tout écart numérique.\n- **Calcul de A(t,T)** :\n  - intégrale \\(\\int_t^T \\theta(s)(1-e^{-\\kappa(T-s)})ds\\) par trapèzes avec un maillage adaptatif (`n ≈ max(64, 80·Δ)`),\n  - variance intégrée OU : `var_integrated_ou(Δ)` en formule fermée."
  }, 
    "src/sim/scenario_engine.py": {
    "title": "Moteur de scénarios — simulation portefeuille (HW1F++ + Log-OU) et calcul CVA/DVA",
    "tags": ["xVA", "CVA", "DVA", "simulation", "portfolio", "HW1F", "LogOU", "EPE", "ENE"],
    "summary": "- **Rôle** : orchestre la simulation **portefeuille** sans dépendance/WWR :\n  1) simule une seule fois des chemins de taux **HW1F++**,\n  2) simule les intensités crédit **Log-OU** (banque + contreparties) de manière indépendante,\n  3) calcule **EPE/ENE** à partir des taux + swaps,\n  4) calcule les legs et agrégats **CVA/DVA**.\n- **Utilisation dans le projet** : point d’entrée “pipeline” pour produire des sorties structurées prêtes pour export/reporting (par contrepartie + totaux).\n- **Objets clés** :\n  - `Simulator` : façade principale.\n  - `_ensure_rate_paths` : cache des chemins de taux `(N, K+1)`.\n  - `_simulate_bank_credit` : cache des profils `PD_bank` / `S_bank` moyens sur la grille.\n  - `run_for_counterparty` : exécute toute la chaîne pour une contrepartie (EPE/ENE + CVA/DVA).\n  - `run_portfolio` : boucle portefeuille + agrégation des legs et des totaux.",
    "usage": "```python\nimport numpy as np\nfrom core.timegrid import TimeGrid\nfrom rates.hw1f import HW1FModel\nfrom rates.zc_pricer import ZCAnalyticHW\nfrom rates.df_curve import DFCurveOnGrid\nfrom credit.entities import Bank, Counterparty\nfrom sim.scenario_engine import Simulator\n\n# Setup commun (grid / modèle / pricers)\ngrid = TimeGrid(T=10.0, K=120)\nrng = np.random.default_rng(2026)\n\nrate_model = HW1FModel(kappa=0.03, sigma=0.01)\n# rate_model.fit_theta_to_curve(ts, grid)  # typiquement fait avant\n\nzc = ZCAnalyticHW(hw=rate_model, ts=ts)\ndf_on_grid = DFCurveOnGrid(ts=ts, grid=grid)\n\nbank = Bank.from_spread(LGD=0.45, spread0=0.010, kappa_lambda=1.2, sigma_lambda=0.25)\n\nsim = Simulator(\n    grid=grid,\n    rate_model=rate_model,\n    zc_pricer=zc,\n    bank=bank,\n    rng=rng,\n    df_curve_on_grid=df_on_grid,\n)\n\n# Contreparties (avec swap driver d'exposition)\ncp1 = Counterparty.from_spread(cid=\"C1\", LGD=0.60, spread0=0.015, kappa_lambda=1.5, sigma_lambda=0.35, swap=swap1)\ncp2 = Counterparty.from_spread(cid=\"C2\", LGD=0.55, spread0=0.012, kappa_lambda=1.3, sigma_lambda=0.30, swap=swap2)\n\nout = sim.run_portfolio([cp1, cp2], N=20000)\n\n# Résultats\nprint(out[\"totals\"][\"CVA_total\"], out[\"totals\"][\"DVA_total\"])\nprint(out[\"per_counterparty\"][0].keys())\n```",
    "notes": "- **Hypothèses** :\n  - pas de dépendance taux/crédit (pas de WWR), pas de corrélation banque/contreparties,\n  - pas de netting/CSA (l’exposition est brute par swap via `ExposureEngine`).\n- **Cohérence à t=0** : `r0` est pris comme `ts.inst_forward(0.0)` (cohérent HW++), et la courbe d’actualisation sur la grille vient de `DFCurveOnGrid`.\n- **Caching** :\n  - les chemins de taux sont calculés une fois par `N` (sinon recalcul),\n  - `PD_bank`/`S_bank` sont calculés une fois et réutilisés pour toutes les contreparties.\n- **Point d’attention RNG** : le même `rng` est consommé successivement pour taux + banque + chaque contrepartie.\n  - C’est OK (indépendance via tirages distincts), mais l’ordre d’exécution impacte la reproductibilité."
  }, 
    "src/xva/cva_dva.py": {
    "title": "Moteur CVA/DVA — calcul par buckets (legs) et agrégation",
    "tags": ["xVA", "CVA", "DVA", "buckets", "EPE", "ENE", "discounting", "credit"],
    "summary": "- **Rôle** : calcule les **legs** de CVA et DVA sur une grille discrète (buckets) puis agrège en montants totaux.\n- **Utilisation dans le projet** : Appelé par `Simulator` (scenario_engine) après obtention de `DF`, `EPE/ENE`, `PD` et `S` pour produire des sorties **par date** (legs) + **totaux** (sommes). \n- Illustrer le calcul de la CVA et de la DVA par bucket réalisé chez Palatine dans le cadre de la réconcialiation des chiffres avec le moteur Amerisc\n- **Objets clés** :\n  - `_as_1d` : normalise les entrées en tableaux 1D et vérifie la forme.\n  - `CVAResults` : conteneur des sorties (`cva_leg`, `dva_leg`, `cva`, `dva`).\n  - `CVAEngine.cva_by_bucket` : applique la formule bucketée de la CVA.\n  - `CVAEngine.dva_by_bucket` : applique la formule bucketée de la DVA avec décalage optionnel de survie.\n  - `CVAEngine.aggregate` / `compute_all` : post-traitement et façade « tout-en-un ». ",
    "usage": "```python\nimport numpy as np\nfrom xva.cva_dva import CVAEngine\n\nKp1 = 121  # K+1\nDF = np.exp(-0.02 * np.linspace(0, 10, Kp1))\nEPE = np.maximum(np.random.normal(1e5, 2e4, size=Kp1), 0.0)\nENE = np.maximum(np.random.normal(8e4, 2e4, size=Kp1), 0.0)\n\nPD_cpty = np.zeros(Kp1); PD_cpty[1:] = 0.001  # exemple (marginal bucket)\nPD_bank = np.zeros(Kp1); PD_bank[1:] = 0.0005\nS_cpty  = np.ones(Kp1)                          # exemple (survie)\n\nres = CVAEngine.compute_all(\n    DF=DF,\n    LGD_cpty=0.60,\n    LGD_bank=0.45,\n    EPE=EPE,\n    ENE=ENE,\n    PD_cpty=PD_cpty,\n    PD_bank=PD_bank,\n    S_cpty=S_cpty,\n)\n\nprint(\"CVA total:\", res.cva)\nprint(\"DVA total:\", res.dva)\nprint(\"CVA_leg shape:\", res.cva_leg.shape)\n```",
    "notes": "- **Formules bucketées (discrètes)** :\n  - `CVA_leg[k] = DF[k] * LGD_cpty * EPE[k] * PD_cpty[k]`\n  - `DVA_leg[k] = DF[k] * LGD_bank * ENE[k] * S_cpty[k-1] * PD_bank[k]` (par défaut via `use_S_prev=True`).\n- **Conventions** : `leg[0]=0` forcé (même si `PD[0]=0`) pour éviter tout artefact."
  }, 
    "src/xva/shapley_explain.py": {
    "title": "Explain Shapley (vectoriel) — décomposition DF / EPE / PD pour les legs CVA et DF / ENE / PD_bank / S pour la DVA",
    "tags": ["xVA", "Shapley", "explainability", "CVA", "DVA", "legs", "DF", "EPE", "ENE", "PD", "survival"],
    "summary": "- **Rôle** : fournit une **décomposition Shapley exacte** (par permutations) de la variation des **legs** CVA/DVA, en attribuant la contribution marginale de chaque « feature » (DF, EPE, PD, etc.) **bucket par bucket**.\n- **Utilisation dans le projet** : Illustrer le travail réalisé chez Palatine sur le calcul des sensibilités des différentes composantes des formules CVA et DVA via les chiffres d'Amerisc\n- **Objets clés** :\n  - `_as_1d` : normalisation/validation des vecteurs 1D.\n  - `_shift_survival` : construit `S_prev[k]=S[k-1]` (avec `S_prev[0]=1`) pour la DVA.\n  - `cva_leg` / `dva_leg` : implémentations locales des formules bucketées (mêmes conventions que le moteur CVA/DVA : `leg[0]=0`).\n  - `shapley_vector` : Shapley **exact** pour une fonction à sortie vectorielle (ici : un leg `(K+1,)`).\n  - `shapley_cva_legs` / `shapley_dva_legs` : wrappers prêts à l’emploi avec les features standard CVA/DVA.",
    "usage": "```python\nimport numpy as np\nfrom xva.shapley_explain import shapley_cva_legs, shapley_dva_legs\n\nKp1 = 121\nLGD_cpty = 0.60\nLGD_bank = 0.45\n\n# --- base run (0)\nDF0 = np.exp(-0.02*np.linspace(0,10,Kp1))\nEPE0 = np.linspace(1e5, 5e4, Kp1)\nPD0  = np.zeros(Kp1); PD0[1:] = 8e-4\n\n# --- new run (1) : choc DF + exposition + PD\nDF1 = np.exp(-0.022*np.linspace(0,10,Kp1))\nEPE1 = 1.10 * EPE0\nPD1  = np.zeros(Kp1); PD1[1:] = 9e-4\n\ncontrib_cva, delta_cva = shapley_cva_legs(DF0,EPE0,PD0, DF1,EPE1,PD1, LGD_cpty)\nprint(\"Delta CVA legs (bucket):\", delta_cva)\nprint(\"Contribution DF:\", contrib_cva[\"DF\"])\nprint(\"Contribution EPE:\", contrib_cva[\"EPE\"])\nprint(\"Contribution PD:\", contrib_cva[\"PD_cpty\"])\n\n# --- DVA (exemple)\nENE0 = np.linspace(8e4, 3e4, Kp1)\nENE1 = 0.95 * ENE0\nPD_bank0 = np.zeros(Kp1); PD_bank0[1:] = 4e-4\nPD_bank1 = np.zeros(Kp1); PD_bank1[1:] = 5e-4\nS0 = np.exp(-0.01*np.linspace(0,10,Kp1))\nS1 = np.exp(-0.012*np.linspace(0,10,Kp1))\n\ncontrib_dva, delta_dva = shapley_dva_legs(DF0,ENE0,PD_bank0,S0, DF1,ENE1,PD_bank1,S1, LGD_bank)\nprint(\"Delta DVA legs:\", delta_dva)\nprint(\"Contribution ENE:\", contrib_dva[\"ENE\"])\n```",
    "notes": "- **Interprétation** :\n  - contribution `DF` capte la part de la variation des legs due à la courbe d’actualisation,\n  - contribution `EPE/ENE` la part due au profil d’exposition,\n  - contribution `PD_*` / `S_cpty` la part due au risque de défaut (marginal) et à la survie."
  }, 
    "src/rates/termstructure/nelson_siegel.py": {
    "title": "Nelson–Siegel — term structure paramétrique (taux zéro, DF, forward instantané)",
    "tags": ["rates", "termstructure", "NelsonSiegel", "yieldcurve", "discounting", "forward"],
    "summary": "- **Rôle** : implémente une courbe Nelson–Siegel en compounding continu pour produire `y(0,T)`, `P(0,T)` et `f(0,t)`.\n- **Utilisation dans le projet** : fournir une `TermStructure` simple et lisse (zéro-coupons + forwards) utilisable par les briques HW++ (`inst_forward`) et les pricers (via `discount_factor`).\n- **Points clés** : stabilité numérique près de 0 via expansions de série pour `h(T)` et limite analytique pour `h'(0)`.",
    "usage": "```python\nfrom rates.termstructure.nelson_siegel import NelsonSiegel\n\n# Exemple de paramètres (taux en décimal, temps en années)\nts = NelsonSiegel(beta0=0.02, beta1=-0.01, beta2=0.015, tau=1.5)\n\nT = 5.0\nprint(\"zero rate:\", ts.zero_rate(T))\nprint(\"DF:\", ts.discount_factor(T))\nprint(\"fwd inst:\", ts.inst_forward(2.0))\n```",
    "notes": "- **Conventions** : discounting en continu `P(0,T)=exp(-y(0,T)T)` ; temps en années ; taux en décimal."
  }

}
